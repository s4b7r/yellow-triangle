{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69037e79-c17d-4cd6-a833-0fda570b23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea3432a9-77e8-4627-8aaf-144c2978607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im = Image.new('1', (128, 128), 0)\n",
    "# mode = '1': black / white\n",
    "# see https://pillow.readthedocs.io/en/stable/handbook/concepts.html#concept-modes\n",
    "draw = ImageDraw.Draw(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b01e3617-06c1-4101-9ed3-88fd0fc0fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw.ellipse((100, 100, 150, 200), fill=(255, 0, 0), outline=(0, 0, 0))\n",
    "#draw.rectangle((200, 100, 300, 200), fill=(0, 192, 192), outline=(255, 255, 255))\n",
    "#draw.line((350, 200, 450, 100), fill=(255, 255, 0), width=10)\n",
    "\n",
    "#im.save('pillow_imagedraw.jpg', quality=95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acc34c74-2e15-480d-b8ed-8cc2d8628a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.regular_polygon((50, 50, 10), 3, rotation=0, fill=None, outline=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5036cbef-fad2-49dc-a0a7-f90f62358c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3ce378e-7ddd-4d56-9fae-7ba46bd7447d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACAAQAAAADrRVxmAAAATUlEQVR4nGNgGAWjYMgABTiLCUIZoAswoAtY4FYBAYwsaCoYMcz4hybAhKHiP5oAC7oKjv8NBFwqwHCAgEvr/z/ALjEKRsEoGAVDDwAAkpEHYS43h2EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=128x128 at 0x1DDB70C39C8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "323befb8-4016-403d-af1c-11f4f7f7f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e89aa884-6e62-43df-af0c-5bb3f0f5549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9b567fc-40bf-4509-84d2-ca6f0c75033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c0ee15b-f80f-4fce-934e-a449b1967408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 126, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 122, 122, 64)      36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 952576)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                60964928  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 61,020,737\n",
      "Trainable params: 61,020,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0fe9c2ea-68a8-452a-8157-249f849c34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8229624-8454-4811-8f8f-2126ba956160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d11bd35-0521-4452-a2d3-86f3cf59eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n",
      "(1, 128, 128)\n",
      "(1, 128, 128, 1)\n",
      "()\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(im)\n",
    "print(train_images.shape)\n",
    "train_images = np.expand_dims(train_images, axis=0)\n",
    "print(train_images.shape)\n",
    "train_images = np.expand_dims(train_images, axis=train_images.ndim)\n",
    "print(train_images.shape)\n",
    "\n",
    "train_labels = np.array((1))\n",
    "print(train_labels.shape)\n",
    "train_labels = np.expand_dims(train_labels, axis=0)\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c6d51d2-cb2d-4497-ba2d-c32c68000ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/sample - loss: 0.4892 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 395ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 233ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 284ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 254ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 264ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 233ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 203ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 234ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 244ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10)#, \n",
    "#                    validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e76b28c7-98fb-411a-9fe0-332a09477d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACAAQAAAADrRVxmAAAAGUlEQVR4nGNgGAWjYBSMglEwCkbBKKAvAAAIgAABVbZk+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=128x128 at 0x1DE40772CC8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_test_blank = Image.new('1', (128, 128), 0)\n",
    "draw = ImageDraw.Draw(im_test_blank)\n",
    "display(im_test_blank)\n",
    "\n",
    "test_images = np.array(im_test_blank)\n",
    "test_images = np.expand_dims(test_images, axis=0)\n",
    "test_images = np.expand_dims(test_images, axis=test_images.ndim)\n",
    "\n",
    "test_labels = np.array((0))\n",
    "test_labels = np.expand_dims(test_labels, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1fac5ea9-8f0f-4fd0-ba76-1ec4f4a5abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1 samples, validate on 1 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 563ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 316ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 306ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1658 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 304ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2007 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 315ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2340 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 329ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2656 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 445ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2954 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 298ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 308ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3499 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 352ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_inclval = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89710479-1a9a-4e92-b657-a059a8eda63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
